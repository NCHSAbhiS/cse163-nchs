{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3c2915e-0384-4c11-b758-d58c931580bc",
   "metadata": {},
   "source": [
    "# File Processing\n",
    "\n",
    "In this lesson, we'll introduce two ways to process files and synthesize what we've learned about debugging. By the end of this lesson, students will be able to:\n",
    "\n",
    "- Read text files line-by-line (line processing).\n",
    "- Read text files token-by-token (token processing).\n",
    "- Write doctests and debug programs using the debugger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31af8b2f-8053-476e-938e-7f1cd47bc904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadb57a1-8b04-4f19-b033-da66fbf190f3",
   "metadata": {},
   "source": [
    "## Opening files in Python\n",
    "\n",
    "In computers, data is stored in **files** that can represent text documents, pictures, structured spreadsheet-like data, etc. For now, we'll focus on files that represent text data that we indicate with the `.txt` file extension.\n",
    "\n",
    "We can open and read files in Python using the built-in `open` function and specifying the **path** to the file. We will talk about file paths in a bit, but think of it like the full name of a file on a computer. The following code snippet opens the file path `poem.txt` and reads the text into the Python variable, `content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227ae0b2-1ad0-4d26-8c75-3c8b78435c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she sells\n",
      "sea\n",
      "shells by\n",
      "the sea shore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"poem.txt\") as f:\n",
    "    content = f.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a4a40-0dcc-417f-b14a-f35036ab2492",
   "metadata": {},
   "source": [
    "The `with open(...) as f` syntax negotiates access to the file with the computer's operating system by maintaining a **file handle**, which is assigned to the variable `f`. (You can use any variable name instead of `f`.) All the code contained in the `with` block has access to the file handle `f`. `f.read()` returns all the contents of the file as string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5e70aa-7bd6-411e-907c-bdef0cecdab1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Line processing\n",
    "\n",
    "It's often useful to read a text file **line-by-line** so that you can process each line separately. We can accomplish this using the `split` function on the content of the file, but Python conveniently provides a `f.readlines()` function that returns all the string text as a list of lines.\n",
    "\n",
    "The following code snippet prints out the file with a line number in front of each line. In this example `lines` will store a list of each line in the file and our loop over that just keeps track of a counter and prints that before the line itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b0d320-31c1-4f20-800a-34e0dbcd3bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 she sells\n",
      "2 sea\n",
      "3 shells by\n",
      "4 the sea shore\n"
     ]
    }
   ],
   "source": [
    "with open(\"poem.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    line_num = 1\n",
    "    for line in lines:\n",
    "        print(line_num, line[:-1]) # Slice-out the newline character at the end\n",
    "        line_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623e33ab-3db9-491b-96e7-25de4cb9ec1b",
   "metadata": {},
   "source": [
    "## Token processing\n",
    "\n",
    "It's also often useful to process each line of text **token-by-token**. A **token** is a generalization of the idea of a \"word\" that allows for any sequence of characters separated by spaces. For example, the string `'I really <3 dogs'` has 4 tokens in it.\n",
    "\n",
    "Token processing extends the idea of line processing by splitting each line on whitespace using the `split` function. In this course, we will use \"word\" and \"token\" interchangeably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "803a3f47-5b97-4680-ab80-464601750754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['she', 'sells']\n",
      "2 ['sea']\n",
      "3 ['shells', 'by']\n",
      "4 ['the', 'sea', 'shore']\n"
     ]
    }
   ],
   "source": [
    "with open(\"poem.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    line_num = 1\n",
    "    for line in lines:\n",
    "        tokens = line.split()\n",
    "        print(line_num, tokens)\n",
    "        line_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f0d195-a230-4d44-825f-9c8f9935c35e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Practice: Count odd-length tokens\n",
    "\n",
    "How might we write a Python code snippet that takes the `poem.txt` file and prints the number of odd-length tokens per line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e202c48-ffa1-49f0-9b94-64a4e5165cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_odd(path):\n",
    "    \"\"\"\n",
    "    For the file path, prints out each line number followed by the number of odd-length tokens.\n",
    "\n",
    "    >>> count_odd(\"poem.txt\")\n",
    "    1 2\n",
    "    2 1\n",
    "    3 0\n",
    "    4 3\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "    with open(\"poem.txt\") as f:\n",
    "        lines = f.readlines()\n",
    "        line_num = 1\n",
    "\n",
    "        for line in lines:\n",
    "            num_odd = 0\n",
    "            tokens = line.split()\n",
    "\n",
    "            for token in tokens:\n",
    "                if len(token) % 2 == 1: \n",
    "                    num_odd += 1\n",
    "                    \n",
    "            print(line_num, num_odd)\n",
    "            line_num += 1\n",
    "\n",
    "doctest.run_docstring_examples(count_odd, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb0db2-0a67-4dc3-b5d1-836dc3961e25",
   "metadata": {},
   "source": [
    "### Practice: Debugging first tokens\n",
    "\n",
    "Let's help your coworker debug a function `first_tokens`, which should return a list containing the first token from each line in the specified file path. They sent you this message via team chat.\n",
    "\n",
    "> Hey, do you have a minute to help me fix this function? There's an error when I run it.\n",
    "\n",
    "Unfortunately, your teammate only provided the code but did not provide any information about the error message, sample inputs to reproduce the problem, or a description of what they already tried.\n",
    "\n",
    "**Let's practice debugging this together and compose a helpful chat response to them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37e68a8e-cb42-4ce5-86fa-b79e49029b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_tokens(path):\n",
    "    result = []\n",
    "    with open(path) as f:\n",
    "        for line in f.readlines():\n",
    "            # new list from line.split() is not being used\n",
    "            # Assign result to variable (token here)\n",
    "            tokens = line.split()\n",
    "            result.append(tokens[0]) #grab first character instead of token\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5800c9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "result += tokens[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9bf7edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "result.extend(tokens[0])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3a8ca5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAbhi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n",
      "\u001b[31mTypeError\u001b[39m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "[] + \"Abhi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8896706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'sea', 'shore']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "result.extend(tokens)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c290d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'sea', 'shore']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85b0d58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "result += [tokens[0]]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d78bf485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'sea']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "result += tokens[0:2]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e66cd8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "result += [ [ tokens[0] ] ]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daafd6d8",
   "metadata": {},
   "source": [
    "line.split() returns a list, but it's not stored anywhere.\n",
    "\n",
    "Assign \n",
    "\n",
    "line[0] is just the first character, not the first token.\n",
    "\n",
    "Use append() instead of += on a list with a string\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
